\documentclass[preprint,12pt]{elsarticle}
\usepackage{amssymb}
\usepackage{todonotes}
\usepackage{color,soul} % For editing highlighting (\hl, \st)

\newcounter{bla}
\newenvironment{refnummer}{%
\list{[\arabic{bla}]}%
{\usecounter{bla}%
 \setlength{\itemindent}{0pt}%
 \setlength{\topsep}{0pt}%
 \setlength{\itemsep}{0pt}%
 \setlength{\labelsep}{2pt}%
 \setlength{\listparindent}{0pt}%
 \settowidth{\labelwidth}{[9]}%
 \setlength{\leftmargin}{\labelwidth}%
 \addtolength{\leftmargin}{\labelsep}%
 \setlength{\rightmargin}{0pt}}}
 {\endlist}

\journal{Computer Physics Communications}

\begin{document}

\begin{frontmatter}
\title{Working Document CPC Paper}

%\begin{abstract}
%This document contains results of work in progress
%\end{abstract}

%\begin{keyword}
%\end{keyword}
\end{frontmatter}

%% ======================================================================
\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

\section{Our contributions}
\begin{itemize}
    \item Application domain has multiple target properties, one per scale (MM and MD). It is much cheaper to evaluate the target in MM than in MD
    \item Domain is assumed to be noisy, multimodal, non-convex: gradient based search will tend to return local optima
    \item \textbf{NOT} SA-CMA-ES: already exists. However, maybe novel: a specific multiscale analysis w.r.t. the quality of solutions found via surrogate-assisted optimization of MM scale, evaluated in MD scale. 
    \item Two-stage approach: First generate a solution set in MM, cluster the solutions to find representatives(?), medoids of the clusters. Then evaluate the medoids in MD domain. 
\end{itemize}

\subsection{Motivation of the research (i.e. the importance of the work))}
\begin{itemize}
    \item Generate new force-field parameters for nonstandard molecular systems, where there is no clear initial set of starting parameters
    \item Reoptimize existing force-field parameters that have been found to posses error with respect to certain observables. Often it is beneficial to explore other areas of parameter space in hopes of locating a solution that results in a lower loss function.
\end{itemize}

\subsection{New Knowledge (i.e. why we will have this published)}
\begin{itemize}
    \item The creation and joining of two separate surrogate models (?) that are used in the low- and high-fidelity optimization (?) models
    \item The usage of new optimization algorithms
    \item Both result in a more computationally efficient approach to exploring parameter space and arriving at possible optimized parameter solutions.
\end{itemize}

\section{Questions}
Questions we need to clarify to the reader and ourselves:
\begin{enumerate}
    \item Why are we not using multi-objective optimization when we have multiple target properties?
    \item Do we have evidence of the domain being noisy, multimodal, non-convex?
    \item MAX and/or ROBIN: A comparison of the AMBER vs. GROMACS functional form of the the force-field equation. How were the parameters transfered from AMBER to GROMACS? If ACPYPE was used, then Austin's work would be sufficient to prove that the underlying PES generated by both programs is nearly equivalent. Such equivalence in the PES is fundamentally required for the optimization scheme to work. 
\end{enumerate}




%% ======================================================================
\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

\section{Summaries of Related Work}
\subsection{ MAX: Machine learning surrogates for molecular dynamics simulations of soft materials}
\begin{itemize}
    \item is about fitting a neural-network based regression model to be in agreement with properties obtained from MD simulations.
    \item input (salt concentration, ion diameter) is used to predict density of a system of ions
    \item Compared to our work: this paper is mainly about replacing MD-based simulations with NN-based regression to save computational time. It is by no means about optimization itself or about force fields.
\end{itemize}

\textit{(Journal of Computational Science)}\cite{kadupitiya2020machine}

\subsection{ MAX: Force-field coefficient optimization of coarse-grained molecular dynamics models with a small computational budget} \textit{(Computational Material Science)}\cite{razi2020force}
\begin{itemize}
    \item Is mainly about multi-fidelity simulation optimization, which can be seen as two-staged optimization I think: ``building stochastic collocation models corresponding to each selected low-fidelity (coarse-grained) model and obtaining the optimal small group of physical input parameter sets at which a high-fidelity model is evaluated''\todo[inline]{AH: I disagree, coarse and fine grained still in the limit describe similar systems, whereas MD and MM have qualitatively different objective surfaces. Is that correct?}
    \item differences: for us, the targets of the cheap-to-evaluate model are of ``high-fidelity''; \item They use a ``heuristic population-based optimization approach''
\end{itemize}

\subsection{Marco: Creating Gaussian process regression models for molecular simulations using adaptive sampling}
\textit{(The Journal of Chemical Physics)} \cite{burn2020creating}\\
\underline{Gemeinsamkeiten:} GP-Regression mit adaptiven Sampling-Strategien, Vorhersage von Energien auf quantenmechanischer Ebene\\
\underline{Hauptunterschied:} keine Vorhersage von makroskopischen Eigenschaften wie Dichte, Transporteigenschaften usw.

\subsection{Robin: Uncertainty quantification in MD simulations. Part II: Bayesian inference of force-field parameters}
\textit{(Multiscale Modeling \& Simulation)} \cite{rizzi2012uncertainty}
\begin{itemize}
    \item \underline{TOPIC:} estimate small-scale, atomistic ff-parameters (Lennard-Jones parameters ($\sigma, \varepsilon$) and distance of between oxygen atom and negative charge of TIP4P model $d$) based on density, self-duffusion and enthalpy of TIP4P water at ambient conditions (NPT) + investigate sensitivity of ff-paramters to target observables
    \item \underline{METHOD:} Bayesian Inference using Polynomial Chaos (PC) Surrogate Models
    \begin{itemize}
        \item create samples using "true" parameters
        \item generate surrogate models based on created samples
        \item reconstruct "true" parameters from surrogate models using bayesian inference
    \end{itemize}
    \item \underline{RESULT:} "true" set of ff-parameters is recoverable with suitable choice of observables lets using low-order surrogate models
    \item \underline{RESULT:} each parameter is very sensitive to certain observables
\end{itemize}
\textbf{Gemeinsamkeiten:} Use of surrogate models; obtaining Lennard-Jones parameters, using macroscale target observables (e.g. density)\\
\textbf{Unterschiede:} Different surrogate model, rather a parameter reconstruction than optimization. Do not use nanoscale target observables\\

\subsection{A Gaussian process surrogate model assisted evolutionary algorithm for medium scale expensive optimization problems (2014) (Alex)} \textit{(IEEE Transactions on Evolutionary Computation)}\cite{liu2013gaussian}

Allow GP-assisted evolutionary optimization for expensive problems with 20-50 decision variables. Framework that reduces training sample dimensionality (DR) to a few dimensions with Sammon mapping before GP model is trained. DR is applied to training locations plus candidate locations.\\ \\
\textbf{Conclusion} The method concentrates on sample dimensionality problems when using GP model in surrogate-assisted evolutionary optimization. Does not have much to do with our work except that it shows that surrogate-assisted optimization is being widely used and improved since the 2010s.

\subsection{Gaussian process surrogate models for the CMA evolution strategy (2018) (Alex)}
\textit{(Evolutionary computation)} \cite{bajer2019gaussian}

Evaluate quite a few variants of surrogate-assisted CMA-ES methods

\textbf{Conclusion}: All methods discussed in the paper are about how to combine (CMA-)ES and surrogate models in various ways. None of the methods handle multiscale problems specifically. But SA-CMA-ES has been around for quite a while.







%% ======================================================================
\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

\section{Related Work on Multiscale Problems}
\todo[inline]{AH: Two interpretations of multiscale. Physics: different scales have different effects. Optimization: different scales of the same function.}



\subsection{How is MM/MD ``done'' in reality, currently? (Robin)}
\paragraph{Development and Testing of the OPLS All-Atom Force Field on Conformational Energetics and Properties of Organic Liquids}
\cite{Jorgensen2996} 
\\ \textbf{tl;dr} Optimizing (torsion) parameters using an simplex algorithm and QM target data.

\paragraph{Multicriteria optimization of molecular force fields by Pareto approach}
\cite{Stoebener2014} 
\\ \textbf{tl;dr} Optimizing ff-parameters towards multiple (macroscale) targets using a pareto approach. 

\paragraph{Development of a new parameter optimization scheme for a reactive force field based on a machine learning approach}
\cite{Nakata2019} 
\\ \textbf{tl;dr} Using Machine Learning approach for parameter optimization.



\subsection{Do approaches exist that algorithmically connect MM and MD? (Max)}
\paragraph{Development and Testing of the OPLS All-Atom Force Field on Conformational Energetics and Properties of Organic Liquids}
\cite{Jorgensen2996}
\\ \textbf{tl;dr} see Robin
\paragraph{Machine Learning Estimates of Natural Product Conformational Energies}
\\ \textbf{description} ``Machine learning has been used for estimation of potential energy surfaces to speed up molecular dynamics simulations of small systems''. No force fields involved
\paragraph{Automated conformational energy fitting for force-field development}
\\ \textbf{description} Fitting ``dihedral or grid-based correction map (CMAP) parameters'' to conformational energies




\subsection{Two-phased optimization, different scales of the same function (Lena)}
\todo[inline]{AH: Helpful keywords: global-local optimization, space mapping, coarse model, fine model, cluster kriging, multilevel surrogate, multi-fidelity, hierarchical surrogate model}
\paragraph{Hierarchical kriging model for variable-fidelity surrogate modeling}
\cite{han2012hierarchical}\\Introducing hierarchical kriging where multiple surrogate-models on different fidelity levels are constructed in order to construct the ones of a higher dimension, i.e. first step define a surrogate model for the low-fidelity function then hierarchically build up as many surrogate models as useful. The higher model does then include the lower ones; as a consequence, the lower surrogate-models assist the predictions that are made with the high-fidelity surrogate model. In contrast to cokriging, it does not require a model of the cross-correlation between the functions. 
\\ \textbf{tl;dr} Hierarchical kriging - a multi-fidelity approach that constructs (stacks up) a hierarchy of surrogate models.
\paragraph{Multifidelity optimization using statistical surrogate modeling for non-hierarchical information sources}
\cite{lam2015multifidelity}\\
Propose a strategy for adaptively constructing a multi-fidelity surrogate when multiple information sources with different fidelities are available. The information sources are not expected to be hierarchical, and each IS is endowed with a fidelity that may vary throughout the design space. 
First, construct an intermediate surrogate for each IS using a Gaussian process to define the mean and associated variance that quantify the uncertainty. Second, construct the multi-fidelity surrogate by merging the information from each intermediate surrogate.
Not each IS has to be evaluated in every iteration of the optimization algorithm; the decision on which one to select is based on a heuristic that weighs the potential information gain and the evaluation cost. Multifidelity- surrogate is updated while optimizing. \\
\textbf{tl;dr} Approach that requires multiple information sources, construct multi-fidelity surrogate model from intermediate surrogates.
\paragraph{Hierarchical surrogate model with dimensionality reduction technique for high-dimensional uncertainty propagation}
\cite{cheng2020hierarchical} \\
Combination of hierarchical surrogate models and dimensionality reduction technique for uncertainty propagation of high-dimensional stochastic problems.
A low-fidelity sparse polynomial chaos expansion model is constructed and used to approximate a high-dimensional function's global behaviour and exploit a low-dimensional active subspace (AS). 
A high-fidelity stochastic Kriging model is built on the reduced space by mapping the high-dimensional data into the identified AS. 
Currently requires a linear Active Subspace (AS).
\\ \textbf{tl;dr} Dimensionality reduction with creation of active subspace, low-fidelity surrogate: sparse polynomial chaos expansion model, high-fidelity: hierarchical kriging
\paragraph{Ensemble of surrogate based global optimization methods using hierarchical design space reduction}
\cite{ye2018ensemble}\\
Construction of three individual surrogate models with optimized weight factors, Original Global Space (OGS), Promising Joint Space (PJS) and Important Local Space (ILS) that are concluded in an ensemble.
The OGS remains invariant during the search and guarantees that the global optimum will not be inadvertently missed. The locations and boundaries of the other two reduced regions, PJS and ILS, change automatically during the iterative search-process due to the augment of promising sample points. PJS is a transition region between the other two; it is calculated by fuzzy c-means clustering and directs the search to a more promising area that contains several currently better solutions. At the same time, the ILS will speed up the search in a smaller and more promising area for the global optimum location.
\\
\textbf{tl;dr} Hierarchical subspaces (dimension reduction) as surrogates concluded in an ensemble.
\paragraph{A multi-fidelity surrogate model based on support vector regression}
\cite{shi2020multi}\\
Proposing a multi-fidelity surrogate model based on support vector regression (Co\_SVR) by combining high-fidelity (HF) and low-fidelity (LF) models. SVR is based on support vector machine (SVM) whose purpose is to evaluate the complex relationship between the input and the response of interest through mapping the data into a high-dimensional feature space. In Co\_SVR, a kernel function is used to map the difference between the HF and LF models. Besides, Grey Wolf optimizer (GWO) is used as a heuristic algorithm to obtain the optimal parameters of Co\_SVR.
\\
\textbf{tl;dr} Multiple surrogate model constructed with SVR.

\paragraph{Multilevel surrogate modeling approach for optimization problems with polymorphic uncertain parameters}
\cite{freitag2020multilevel} 
Proposing a concept that allows considering uncertain a priori parameters and uncertain design parameters quantified by stochastic numbers and intervals with a neural-network-based surrogate modelling approach. In the case of FE simulations, a first artificial neural network is trained to approximate the deterministic finite element analysis used to create a second neural network to replace the stochastic analysis (Monte Carlo simulation). 
\\ \textbf{tl;dr} Finite Elemente Simulation -using two ANN as different levels of surrogates

\paragraph{A multi-fidelity RBF surrogate-based optimization framework for computationally expensive multi-modal problems with application to capacity planning of manufacturing systems}
\cite{yi2020multi} \\
The proposed multi-fidelity RBF (radial basis function) surrogate-based optimization framework (MRSO) approach has three main steps:
\begin{enumerate}
    \item Search on the LF model with DYCORS (dynamic coordinate search algorithm using response surface) algorithm (to build and update RBF surrogate model of LF model).
    \item Potential area detection procedure (search on LF surrogate and cluster local optima $\rightarrow$ starting points for HF).
    \item The search on the HF model (build and update RBF HF surrogate).
\end{enumerate}
\\ \textbf{tl;dr} Two-level RBF surrogate  

\paragraph{A generalized hierarchical co-Kriging model for multi-fidelity
data fusion}
\cite{zhou2020generalized} uses a multifidelity surrogate-assisted approach that adjusts the surrogate built on low fidelity samples with a few (nested) high fideltiy samples. 
\\ \textbf{tl;dr} Multifidelity approach that connects high and low fidelity models (models, not surrogate models).


\subsection{Do approaches exist that connect two levels of theory in (surrogate-assisted) optimization? different functions on levels of scale of underlying physical system (Alex)}

\paragraph{Multiscale surrogate modelling of the elastic response of thick composite structures with embedded defects and features.} Treating thick laminated fibre reinforced composite materials containing internal defects and features, \cite{el2018multiscale} connects meso-scale Representative Volume Element models to a surrogate model that acts on the macro-scale, using 3D lamination parameters. \\ \textbf{tl;dr} this approach is specific to its domain.

\paragraph{An efficient multiscale surrogate modelling framework for composite materials considering progressive damage based on artificial neural networks.} 
\cite{yan2020efficient} treats progressive damage behaviour of large-scale composite structures and propose a method to accelerate the nonlinear FE analysis by using a pre-computed surrogate model which acts as a general material database representing. The surrogate model is first trained with a vast number of sampling data obtained from mesoscale unit cell models offline, and then used for online predictions on a macroscale FE model
\\ \textbf{tl;dr} this approach uses two phases: offline and then online. Our approach uses only online phases.

\paragraph{\hl{On-the-fly construction of surrogate constitutive models for concurrent multiscale mechanical analysis through probabilistic machine learning.}}
\cite{rocha2020fly} uses GP surrogate models to replace micromodels in a macro-micro FE mechanical analysis. Microlevel GP models are trained online based on anchor micromodels that are selected based on macroscopic integration points. The GP models' uncertainty is used to trigger new anchor micromodels. The goal is to reduce the number of microlevel evaluations. GP models are enhanced with gradient information. 
\\ \textbf{tl;dr} This approach comes very close to what we are doing although no surrogate model is used for the macroscopic level. \textbf{Recommendation}: for all to read.

\paragraph{Surrogate modeling of multiscale models using kernel methods}
\cite{wirtz2015surrogate} uses microlevel (kernel method based) surrogate models to connect macro-micro optimization. 
\\ \textbf{tl;dr} Single-level surrogates

\paragraph{On-the-fly adaptivity for nonlinear twoscale simulations using artificial neural networks and reduced order modeling}
\cite{fritzen2019fly} propose a multi-fidelity surrogate model for highly nonlinear multiscale problems. It is based on the introduction of two different surrogate models and an adaptive on-the-fly switching. The two concurrent surrogates are built incrementally starting from a moderate set of evaluations of the full order model. 
\\ \textbf{tl;dr} Concentrates on the surrogate modeling problem at two different scale, not so much optimization


\section{Notes for next meeting}
\begin{itemize}
    \item AH: we need to position our approach within the vast web of multi-* approaches. In our problem, we have different physical features on different scale levels. Each scale level is modeled with its own model. The approach uses surrogate models for each of the scale levels. Optimization is performed on both scale levels in an online sequential manner. The first step is bootstrapped, using a space filling sampling. The second step is \textbf{not} bootstrapped and uses the results of the first step as an initial starting position. Remark: all intermediate results of the first step are used.
    \begin{itemize}
    \item \textbf{multi-level}: multiple surrogates that each represent a different level, for example when an optimization process consists of a global and local optimization step, but higher-level surrogates are used as well.
    \item \textbf{multi-scale}: having important features at multiple scales in time or space.
    \item \textbf{multi-fidelity}: using coarse and fine models, usually the coarse model is a surrogate and the fine model a numerical simulation. 
    \item \textbf{multi-physics}: coupled processes involving more than one simultaneously occurring physical field
    \item \textbf{multi-objective}: having more than one objective. We combine both objectives (in the end) in the mixed objective function. However, the two objectives still do exist.
    \end{itemize}
    \item AH: ours is a nested approach ``nested: the high fidelity sampling set is a subset of the low fidelity one''. 
    
\end{itemize}

%% ======================================================================
\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}


\bibliographystyle{elsarticle-num}
\bibliography{Lit.bib}

%% Authors are advised to submit their bibtex database files. They are
%% requested to list a bibtex style file in the manuscript if they do
%% not want to use elsarticle-num.bst.

%% References without bibTeX database:

% \begin{thebibliography}{00}

%% \bibitem must have the following form:
%%   \bibitem{key}...
%%

% \bibitem{}

% \end{thebibliography}


\end{document}

%%
%% End of file 